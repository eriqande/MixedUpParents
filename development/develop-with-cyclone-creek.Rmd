---
title: "Developing the method with cyclone creek"
output: html_document
date: "2023-08-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Record the name of the pop we are doing:
```{r}
POP <- "CycloneCreek"
```

First off, let's get the diagnostic markers done up for them.  This block
does not get evaluated in this notebook, because I do it in a terminal
R session so that I can use future and give it 8 cores.
```{r, eval=FALSE}
library(tidyverse)
library(MixedUpParents)

DIAG_PATH <- paste0("BigData/", POP, "/Processed/spp_diagnostics.rds")
# get test data set as M
M <- read_rds(DIAG_PATH)

# find the ancestral-n-segments
D <- ancestral_n_segments(M, unique(M$chrom))

#' find the extended segments:
#' set the number of cores:
future::plan(future::multicore, workers = 8)  # 8 cores on my laptop


# extend those ancestral segments
E <- extend_ancestral_segments_3(D, c("WCT", "RBT", "YCT"))
# That takes a while because the Intervals package functions
# are pretty darn slow.

# write that out:
EXTEND_PATH <- paste0("BigData/", POP, "/Processed/extended_anc_segs.rds")
write_rds(E, file = EXTEND_PATH, compress = "xz")
```

Now, we can read that in:
```{r}
library(tidyverse)
library(MixedUpParents)
VAR_PATH <- paste0("BigData/", POP, "/Processed/var_sites.rds")
DIAG_PATH <- paste0("BigData/", POP, "/Processed/spp_diagnostics.rds")
EXTEND_PATH <- paste0("BigData/", POP, "/Processed/extended_anc_segs.rds")

OUTDIR <- file.path("dev-results", POP)
dir.create(OUTDIR, recursive = TRUE, showWarnings = FALSE)
E <- read_rds(EXTEND_PATH)
```


## Plotting the fraction of different ancestry copy numbers

We have a function to make a barplot of the fraction of different ancestry
copy numbers. Here it is:
```{r, fig.width=10, fig.height=10, dev='svg'}
barplot <- ancestry_barplot(E)
barplot
```

Note that `A2B0C0` refers to a location in the genome where the individual
carries two copies of WCT ancestry.  `A1B1C0` is where it has 1 copy of 
WCT and 1 copy of RBT.  `A0B2C0` is two copies of RBT ancestry.  C is the YCT ancestry.  

Just a note that this plot is easier to see as a PDF.  Here as SVG it is not 
bad, but you can't zoom very far in it.

```{r}
ggsave(barplot, filename = file.path(OUTDIR, "ancestry_barplot.pdf"), width = 10, height = 12)
```

## Plotting every ancestry copy-number segement in every individual

There is also a function that creates a ridiculous plot of all the segments
in all the individuals on all the chromosomes. The first flavor of this has
just a single bar for each individual.  (Later I might do one that has two
"haplotypes" for each individual).

This uses the same function as the above, with a different option:
```{r, fig.width=10, fig.height=30, dev='svg'}
segplot <- ancestry_barplot(E, plot_type = "segments")
segplot
```

The chromosomes are all stacked upon one another in this plot.  So, each column is
an individual, and every thin horizontal black line shows where a chromsome ends.
The chromosomes actually end before and after those lines, but we have discarded 
parts of the chromosomes that are outside of any species-diagnostic markers.

Once again, that is much better to look at in PDF form.  

## Add the species-diagnostic markers to that plot

You can pass the data frame of species diagnostic markers to that plot
to see where they all fall out with respect to the segments. This one
is definitely best looked at as a PDF.  
```{r}
# read in the species diagnostic markers and
# prepare the data frame so that the species designations
# are A, B, and C.
M <- read_rds(DIAG_PATH) %>%
  mutate(
    diag_spp = case_match(
      diag_spp,
      "WCT" ~ "A",
      "RBT" ~ "B",
      "YCT" ~ "C"
    )
  )

# then we can pass that in like so:
SDM_plot <- ancestry_barplot(E, plot_type = "segments", diagnostic_markers = M)

# this one requires PDF to view reasonably.  So, do that:
ggsave(SDM_plot, filename = file.path(OUTDIR, "stacked_segs.pdf"), width = 10, height = 30)

rm(SDM_plot)
```


## Estimating allele frequencies

This part should be pretty mellow.  For the scale of data we have,
we ought to be able to just left join the variable genotypes by
individual and chromosome, and then filter out things that are not
included in ancestral-copy-number-inferred segments.

```{r}
source("../R/estimate_allele_freqs_EM.R")
V <- read_rds(VAR_PATH)

afem_list <- estimate_allele_freqs_EM(E, V)
AlleFreqs0 <- afem_list$alle_freqs %>%
  mutate(tot_obs = n0 + n1 + nu0 + nu1 - 1)
GenoCounts <- afem_list$geno_counts
```


The output of AlleFreqs0 is a little complex:
```{r}
head(AlleFreqs0)
```

Now, it looks like some of the markers don't have any observations in some of the ancestries:
```{r}
AlleFreqs0 %>% 
  ggplot(aes(x = tot_obs, fill = Ancestry)) +
  geom_histogram() +
  facet_wrap(~Ancestry) 
```

We expect that in the Yellowstone Cutthroat ancestry (C), but the 140 or so loci that
have no observations in the WCT ancestry is kind of concerning.  That means that there
are some markers that are NA in all the WCT ancestry, which is most of it.  What gives?
Which markers are those?
```{r}
tot_obs0_markers <- AlleFreqs0 %>% 
  filter(
    Ancestry == "A",
    tot_obs < 10
  )
```

That is 137 markers.  What do we see at those markers in the data set?
```{r}
GenosOfWonkies <- V %>%
  semi_join(
    tot_obs0_markers %>% mutate(chrom = as.character(chrom_f)),
    by = join_by(chrom, pos)
  )

# and to get the result we have, we would expect that these are predominantly missing
# in the data set
GenosOfWonkies %>%
  group_by(var_spp, chrom, pos) %>%
  summarise(fract_missing = mean(is.na(n)))

```

Hmmm...none of these have a high enough fraction of missing data to be believable, since the
fraction of WCT ancestry amongst all the fish is clearly on the order of 70% to 80%. So
this makes no sense.  

Hold on! The problem is that they are not within the bounds of any diagnostic markers, so we
can't determine ancestry for them.  Frick!  We are going to need to drop those.  In fact,
we should drop any that don't have at least 100 total observations.  

And, while we are at it, I am going to chuck the Yellowstones as well.
Here we go.
```{r}
AlleFreqs <- AlleFreqs0 %>%
  filter(Ancestry != "C") %>%
  group_by(chrom_f, pos) %>%
  filter(min(tot_obs) > 100)
```



Let us see how much allele frequencies changed as a result of doing the EM:
```{r}
ggplot(AlleFreqs, aes(x = p_init1, y = pnew1, colour = Ancestry)) +
  geom_point() +
  facet_wrap(~ Ancestry)
```

OK, so most of the frequencies in the RBT background are different after including
the individuals that are heterozygous for both the ancestry and the alleles.

Now, I want to color it according to whether the locus was considered to be a WCT-
or an RBT-variable marker.
```{r}
AlleFreqs %>%
  left_join(
    V %>% 
      distinct(var_spp, chrom, pos) %>% 
      mutate(chrom_f = factor(chrom, levels = levels(AlleFreqs$chrom_f))),
    by = c("chrom_f", "pos")
  ) %>%
  ggplot(aes(x = p_init1, y = pnew1, colour = var_spp)) +
  geom_point() +
  facet_wrap(~ Ancestry)
```

Well, that is super weird.  I've spot checked a few of them, and it seems that the
allele in question shows up occasionally in the homozygous RBT, and sometimes in homozygous
form in the WCT/RBT hets.  

Let's color the points by the frequency of the allele in WCT:
```{r}
AlleFreqs %>%
  group_by(chrom_f, pos) %>%
  mutate(WCTfreq1 = pnew1[Ancestry == "A"]) %>%
  ggplot(aes(x = p_init1, y = pnew1, colour = WCTfreq1)) +
  geom_point() +
  facet_wrap(~ Ancestry) +
  scale_colour_viridis_c()
```

OK, these are basically mostly SNPs that are effectively mononorphic in the WCT background,
but which are polymorphic in RBT.  Gonna have to think on that a little bit...

**After a long hiatus, I am returning to this while at the ConGen**

I actually think this is OK.  One thing I would like to check is that the expected proportions
of genotypes _within_ each of the different backgrounds, are what we would expect
with random drawing of alleles onto each background. Basically, if we let
$p_{A0}$ and $p_{A1}$ be the estimated freqs of alleles 0 and 1 on the $A$ background,
and $p_{B0}$ and $p_{B1}$ be the same on the $B$ background, then for the three
relevant different ancestries we have:
$$
\begin{aligned}
\mathrm{Ancestry} &  ~~~~~~~~~~~\mathrm{Genotype} &~ \mathrm{Prob~of~genotype} \\
A_2B_0C_0  &~~~~~~~~~~~~    0    &~   p_{A0}^2 \\
  &~~~~~~~~~~~~    1    &~   2p_{A0}p_{A1} \\
  &~~~~~~~~~~~~    2    &~   p_{A1}^2 \\
\\
A_0B_2C_0  &~~~~~~~~~~~~    0    &~   p_{B0}^2 \\
  &~~~~~~~~~~~~    1    &~   2p_{B0}p_{B1} \\
  &~~~~~~~~~~~~    2    &~   p_{B1}^2 \\
\\
A_1B_1C_0  &~~~~~~~~~~~~    0    &~   p_{A0}p_{B0} \\
  &~~~~~~~~~~~~    1    &~   p_{A0}p_{B1} + p_{B0}p_{A1} \\
  &~~~~~~~~~~~~    2    &~   p_{A1}p_{B1} \\
\end{aligned}
$$


So, we can calculate the expected number of genotypes in each ancestry group
for each locus.  

Let's make a tibble that has all those frequencies for each allele, and then
calculate these genotype frequencies for different ancestries.
```{r}
expected_geno_freqs <- AlleFreqs %>%
  filter(Ancestry %in% c("A", "B")) %>%
  select(chrom_f, pos, Ancestry, starts_with("pnew")) %>%
  rename(p0 = pnew0, p1 = pnew1) %>%
  pivot_wider(
    names_from = Ancestry,
    values_from = c(p0, p1),
    names_sep = ""
  ) %>%
  expand_grid(
    copy_num = c("A2B0C0", "A1B1C0", "A0B2C0"),
    .
  ) %>%
  arrange(chrom_f, pos, copy_num) %>% # this has given us the copy nums and the alle freqs and now we compute the prob of 0, 1, or 2, genos
  mutate(
    Pg0 = case_when(
      copy_num == "A2B0C0" ~ p0A ^ 2,
      copy_num == "A0B2C0" ~ p0B ^ 2,
      copy_num == "A1B1C0" ~ p0A * p0B
    ),
    Pg1 = case_when(
      copy_num == "A2B0C0" ~ 2 * p0A * p1A,
      copy_num == "A0B2C0" ~ 2 * p0B * p1B,
      copy_num == "A1B1C0" ~ p0A * p1B + p1A * p0B
    ),
    Pg2 = case_when(
      copy_num == "A2B0C0" ~ p1A ^ 2,
      copy_num == "A0B2C0" ~ p1B ^ 2,
      copy_num == "A1B1C0" ~ p1A * p1B
    )
  ) %>%
  select(-(p0A:p1B)) %>%
  pivot_longer(
    cols = c(Pg0, Pg1, Pg2),
    names_to = "geno", 
    values_to = "exp_GP"
  ) %>%
  mutate(geno = as.integer(str_sub(geno, 3, 3)))
```

OK! That gave us the expected genotype frequencies.

Now, we want to take the observed genotype counts, complete them, and then
calculate their relative freqs.
```{r}
observed_geno_freqs <- GenoCounts %>% 
  semi_join(AlleFreqs, by = join_by(chrom_f, pos)) %>%
  filter(copy_num %in% c("A2B0C0", "A1B1C0")) %>%
  complete(
    nesting(chrom_f, pos), copy_num, geno,
    fill = list(n = 0L)
  ) %>%
  group_by(chrom_f, pos, copy_num) %>%
  mutate(
    obs_GP = n / sum(n)
  )
  
```

Now we can compare those:
```{r}
exp_and_obs_geno_freqs <- observed_geno_freqs %>%
  left_join(expected_geno_freqs, by = c("chrom_f", "pos", "copy_num", "geno"))
```

Plot them in a big facet_grid
```{r}
ggplot(exp_and_obs_geno_freqs, aes(x = exp_GP, y = obs_GP, colour = copy_num)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  facet_grid(copy_num ~ geno)
```

That is pretty great.  It looks much like we would expect it to. There are clearly
a couple of loci that are not modelled super well.  Let us colour these points
by some sort of significance value for being off the line.  We could colour them by
a z-score given the expected binomial proportion and the associated variance/sd:

```{r}
exp_and_obs_geno_freqs_2 <- exp_and_obs_geno_freqs %>%
  group_by(chrom_f, pos, copy_num) %>%
  mutate(tot_n = sum(n)) %>%
  ungroup() %>%
  mutate(z_score = (exp_GP - obs_GP) * sqrt(tot_n / (exp_GP * (1 - exp_GP))))

# first look at the distribution of the z_scores
ggplot(exp_and_obs_geno_freqs_2, aes(x = z_score)) +
  geom_histogram()
```

Wow! There are a tiny few that are totally wonky.  So, let's filter a bit
so that they are not pulling our color scale too far out.

```{r}
exp_and_obs_geno_freqs_2 %>%
  filter(abs(z_score) < 9) %>%
  ggplot(aes(x = exp_GP, y = obs_GP, colour = abs(z_score))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  facet_grid(copy_num ~ geno) +
  scale_colour_viridis_c()
```
OK.  There are a few that are sort of out.  But it is not too, too many.

Let's plot the histogram after this sort of filtering:
```{r}
exp_and_obs_geno_freqs_2 %>%
  filter(abs(z_score) < 9) %>%
  ggplot(aes(x = z_score)) +
  geom_histogram() +
  facet_grid(copy_num ~ geno)
           
```


So, how many markers are we left with if we filter out those that have nothing
as bad as $|z| > 4.09$ (which gives a cumulative prob of 1 out of 1000; so, it is like
a p-value of 0.001) within the copy_num at a site.

```{r}
exp_and_obs_geno_freqs_3 <- exp_and_obs_geno_freqs_2 %>%
  group_by(chrom_f, pos, copy_num) %>%
  filter(all(abs(z_score) < 4.09))


ggplot(exp_and_obs_geno_freqs_3, aes(x = exp_GP, y = obs_GP, colour = abs(z_score))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  facet_grid(copy_num ~ geno) +
  scale_colour_viridis_c()
```
Let's see how many loci this is, total
```{r}
exp_and_obs_geno_freqs_3 %>%
  ungroup() %>%
  count(chrom_f, pos)
```
Still quite a few.  

Let's look at the estimated allele frequencies of these.   We will look at the
frequency of the 1 allele in each case.
```{r}
retained_freqs <- AlleFreqs %>% 
  semi_join(exp_and_obs_geno_freqs_3, by = c("chrom_f", "pos")) %>%
  filter(Ancestry != "C") %>%
  mutate(MAF = pmin(pnew1, 1 - pnew1))

ggplot(retained_freqs, aes(x = MAF)) +
  geom_histogram() + 
  facet_wrap(~Ancestry, nrow = 1)
```


So, let's count up the MAFs:
```{r, rows.print=30}
retained_freqs2 <- retained_freqs %>%
  mutate(maf_bin = cut_width(MAF, 0.05))

retained_freqs2 %>%
  ungroup() %>%
  count(Ancestry, maf_bin)
```

So, that is pretty cool.   Let's count up the total number of markers
in each genetic background with allele frequencies greater then 0.125:
```{r}
retained_freqs2 %>%
  group_by(Ancestry) %>%
  summarise(numLoc_gt_12.5 = sum(as.integer(maf_bin) > 3))
```

So, those are pretty decent numbers of markers that we will have to work with, I think. Not great, but it
might prove enough...

We are, however, going to retain as many loci as possible though, so we will use a smaller then
12.5% MAF cutoff, below.

From these.  Let's see how different the frequencies in A and B background are at all
of these.  My guess is that they are probably fixed in the other background, for the most part.
```{r}
keepers_gt_12.5 <- retained_freqs2 %>%
  filter(as.integer(maf_bin) > 3) %>%
  select(chrom_f, pos, Ancestry, MAF) %>%
  pivot_wider(names_from = Ancestry, values_from = MAF, values_fill = 0L)

ggplot(keepers_gt_12.5, aes(x = A, y = B)) +
  geom_point()
```

So, it looks like some of these are polymorphic in both backgrounds.

I think we are going to be good do go with these to further develop the
methodology.

Let us now make a data set to plot the locations of these on the segments plot.
Let's keep the SNPs with a MAF > 0.01 in either of the backgrounds/

```{r}
retained_freqs_maf_gt01 <- retained_freqs2 %>%
  group_by(chrom_f, pos) %>%
  filter(any(MAF > 0.01)) %>%
  select(chrom_f, pos, Ancestry, MAF, pnew1)

```


That removes something like 230 markers. Is that reasonable?  We can check that by looking at the
orginal data.  We can find the ones that got
removed like this:
```{r}
sites_below_MAF0.1_in_both <- retained_freqs2 %>% filter(all(MAF < 0.01)) %>%
  count(chrom_f, pos) %>%
  mutate(chrom = as.character(chrom_f))

# then we could extract those from the original data set and calculate
# frequencies of the 1 allele.
V %>%
  semi_join(sites_below_MAF0.1_in_both, by = join_by(chrom, pos)) %>%
  filter(!is.na(n)) %>%
  group_by(var_spp, chrom, pos) %>%
  summarise(
    alle1cnt = sum(n),
    tot_num = 2 * n(),
    freq1 = alle1cnt / tot_num
  )
```

Now, to continue this, we also need a tibble of the allele freqs, but not of the MAFs,
we want the freq of the 1 allele, and we want it so we can join it to the
intersected intervals later on.
```{r}
VarFreqs <- retained_freqs_maf_gt01 %>%
  select(-MAF) %>%
  pivot_wider(names_from = Ancestry, values_from = pnew1) %>%
  ungroup()

VarFreqs
```


We are going write out those allele frequencies, now, too.
```{r}
write_csv(VarFreqs, file = file.path(OUTDIR, "variable_marker_freqs.csv"))
```


# Now, get the genotypes of individuals at those markers

```{r}
Vuse <- V %>%
  semi_join(VarFreqs %>% mutate(chrom = as.character(chrom_f)), by = join_by(chrom, pos)) %>%
  select(-var_spp) %>%
  rename(G = n)
  
head(Vuse)
```


And write those out:
```{r}
write_rds(Vuse, file = file.path(OUTDIR, "variable_marker_genotypes.rds"), compress = "xz")
```


# Check that the frequencies look reasonable

I am going to do a sanity check here, looking at WCT to see if I have allele 0 and 1 oriented
correctly in the estimated freqs.  There is about 12% RBT ancestry, so I should be able to
just look at the raw freqs of things and compare to the estiamted ones.
```{r}
VV <- V %>%
  semi_join(VarFreqs %>% mutate(chrom = as.character(chrom_f)), by = join_by(chrom, pos)) %>%
  filter(!is.na(n)) %>%
  group_by(chrom, pos) %>%
  summarise(
    ac = sum(n),
    tc = 2 * n(),
    af = ac / tc
  )

VVC <- VV %>%
  left_join(VarFreqs %>% mutate(chrom = as.character(chrom_f)), by = join_by(chrom, pos))

ggplot(VVC, aes(x = A, y = af)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", colour = "blue")


```

```{r}
ggplot(VVC, aes(x = B, y = af)) +
  geom_point()
```


## Intersecting intervals, etc.

First thing, let's make the integer representation of E:
```{r}
ir_E <- integer_representation_EAS(E)
```

That is easy.  Now, we should be able to intersect any individuals that we want to.  Let's see what happens if we intersect
individual 0 with all the rest:
```{r}
indiv0_intersected_to_everyone <- intersect_ancestry_intervals_rcpp(
  grp1 = 0,
  grp2 = 1:(ir_E$nIndiv - 1), 
  nC = ir_E$nChrom, 
  V1 = ir_E$IntervalsMatrix, 
  V2 = ir_E$IntervalsMatrix, 
  X1 = ir_E$IndexMatrix, 
  X2 = ir_E$IndexMatrix, 
  nv1 = ir_E$nIntvlsVec, 
  nv2 = ir_E$nIntvlsVec
)
```

That is super fast.  What about if we intersect everyone against everyone else,
but we don't actually keep track of the results (to save memory---we are just trying
to see how fast this is).

```{r}
system.time(for(i in 0:(ir_E$nIndiv - 1)) {
  biff <- intersect_ancestry_intervals_rcpp(
    grp1 = i,
    grp2 = setdiff(0:(ir_E$nIndiv - 1), i),
    nC = ir_E$nChrom, 
    V1 = ir_E$IntervalsMatrix, 
    V2 = ir_E$IntervalsMatrix, 
    X1 = ir_E$IndexMatrix, 
    X2 = ir_E$IndexMatrix, 
    nv1 = ir_E$nIntvlsVec, 
    nv2 = ir_E$nIntvlsVec
  )
  #print(i)
})
```

OK.  That is super fast.  About 1.5 million pairs per second.  

Now, what we need to do is add a way to quickly calculate the probability of
the genotypes (and hence the likelihood ratio)
for each intersected pair.  

I have decided we are not going to do those calculation in RCpp, because we can just do all of them
vectorized for a single individual compared to everyone else.  So, we need to make a tibble out of the 
matrix spoing and add chromosomes and indivs back on there.
```{r, eval=FALSE}
colnames(indiv0_intersected_to_everyone) <- c("Idx1", "Idx2", "Cidx", "anc1", "anc2", "start", "stop")
indiv0_ite_tibble <- as_tibble(indiv0_intersected_to_everyone) %>%
  left_join(ir_E$iKey, by = join_by(Idx1 == idx)) %>%
  rename(ind1 = indiv) %>%
  left_join(ir_E$iKey, by = join_by(Idx2 == idx)) %>%
  rename(ind2 = indiv) %>%
  left_join(ir_E$cKey, by = join_by(Cidx == idx))

# now, join this to the variants and filter out things not in intersected
# intervals

OneToAll <- indiv0_ite_tibble %>%
  left_join(Vuse %>% rename(ind1 = indiv, G1 = G), by = join_by(chrom, ind1)) %>%
  filter(start < pos & pos < stop) %>%
  left_join(Vuse %>% rename(ind2 = indiv, G2 = G), by = join_by(chrom, pos, ind2)) %>%
  left_join(
    VarFreqs %>% mutate(chrom = as.character(chrom_f)) %>% select(-chrom_f) %>% rename(pA = A, pB = B),
    by = join_by(chrom, pos)
  )


```

That is what we can start calculating likelihoods of different pairs with.  Let's have a look at this thing:
```{r, eval=FALSE}
head(OneToAll)
```

Because we are comparing `Idx1` to everyone else, here, we will take `Idx1` to be
the Kid that we are comparing to lots of different candidate parents, so
`idx2` will be the parents.  So, to make things easy, and to have them correspond
to the notation in the paper, we will just make some new columns that are named
according to the notation in the paper. And, at the same time, we will find the points
where the parent has a new tract of heterozygous ancestry, as those will be
the ones where the segregation probability is 1/2 for only one of the markers,
and 1 everywhere else, because we assume that it is all physically linked. In fact,
since we have all the markers here, for each of those contiguous heterozygous tracts
in a candidate parent, we will record one element of the `seg_factor` column as
1/2 and the rest as 1, so we can just include those, vectorized in the calculations
which will then get properly multipled together over loci (really summed over the logs)
within each kid x candidate-parent pair.  Note that we will put seg_factor = 1/2 at the
first place where neither genotype (Gpar or Gkin) is NA.
```{r, eval=FALSE}
OneToAll2 <- OneToAll %>%
  select(pA, pB, everything()) %>%
  mutate(
    Hpar = Idx2,
    Hkid = Idx1,
    Gpar = G2,
    Gkid = G1,
    seg_factor = 1,  # by default, the segregation prob for each marker will 1 and one of them will become 1/2 for heterozygous parents.  
    .before = pA
  )
  
```

